{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from Story.get_board import Board\n",
    "from Audio.get_voices import Voices\n",
    "from Audio.gen_audio import generate_audio, process_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import settings\n",
    "\n",
    "PLAY_HT_API_KEY = config.PLAY_HT_API_KEY\n",
    "PLAY_HT_USER_ID =  config.PLAY_HT_USER_ID\n",
    "\n",
    "BOARD_URL = settings.BOARD_URL\n",
    "JSON_PATH = settings.JSON_PATH\n",
    "BOARDS_PATH = settings.BOARDS_PATH\n",
    "\n",
    "VOICE_DICT = settings.VOICE_DICT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playht = Voices()\n",
    "\n",
    "voices = playht.get_voices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       | name     | sample                                                                   | accent   | age   | gender | language     | language_code | loudness | style       | tempo   | texture  | is_cloned | \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "adolfo   | Adolfo   | https://peregrine-samples.s3.amazonaws.com/editor-samples/adolfo.wav     | american | adult | male   | English (US) | en-US         | neutral  | narrative   | fast    | thick    | False     | \n",
      "alfonso  | Alfonso  | https://peregrine-samples.s3.amazonaws.com/editor-samples/alfonso.wav    | american | adult | male   | English (US) | en-US         | neutral  | videos      | neutral | gravelly | False     | \n",
      "Anthony  | Anthony  | https://peregrine-samples.s3.amazonaws.com/editor-samples/Anthony.wav    | american | adult | male   | English (US) | en-US         | neutral  | training    | slow    | thick    | False     | \n",
      "Axel     | Axel     | https://peregrine-samples.s3.amazonaws.com/editor-samples/Axel.wav       | american | adult | male   | English (US) | en-US         | neutral  | narrative   | fast    | thick    | False     | \n",
      "bryan    | Bryan    | https://peregrine-samples.s3.amazonaws.com/editor-samples/bryan.wav      | american | adult | male   | English (US) | en-US         | low      | videos      | fast    | gravelly | False     | \n",
      "Carter   | Carter   | https://peregrine-samples.s3.amazonaws.com/editor-samples/Carter.wav     | american | adult | male   | English (US) | en-US         | neutral  | narrative   | neutral | thick    | False     | \n",
      "charles  | Charles  | https://peregrine-samples.s3.amazonaws.com/editor-samples/charles.wav    | american | adult | male   | English (US) | en-US         | neutral  | narrative   | neutral | round    | False     | \n",
      "dane     | Dane     | https://peregrine-samples.s3.amazonaws.com/editor-samples/dane.wav       | american | adult | male   | English (US) | en-US         | neutral  | videos      | neutral | round    | False     | \n",
      "daniel   | Daniel   | https://peregrine-samples.s3.amazonaws.com/editor-samples/daniel_vo.wav  | canadian | adult | male   | English (US) | en-US         | low      | narrative   | neutral | smooth   | False     | \n",
      "darnell  | Darnell  | https://peregrine-samples.s3.amazonaws.com/editor-samples/darnell.wav    | american | youth | male   | English (US) | en-US         | neutral  | narrative   | neutral | smooth   | False     | \n",
      "dick     | Dick     | https://peregrine-samples.s3.amazonaws.com/editor-samples/dick.wav       | american | adult | male   | English (US) | en-US         | neutral  | training    | fast    | smooth   | False     | \n",
      "donovan  | Donovan  | https://peregrine-samples.s3.amazonaws.com/editor-samples/donovan.wav    | american | adult | male   | English (US) | en-US         | low      | narrative   | neutral | smooth   | False     | \n",
      "efren    | Efren    | https://peregrine-samples.s3.amazonaws.com/editor-samples/efren.wav      | american | adult | male   | English (US) | en-US         | neutral  | training    | slow    | thick    | False     | \n",
      "harold   | Harold   | https://peregrine-samples.s3.amazonaws.com/editor-samples/harold.wav     | american | adult | male   | English (US) | en-US         | neutral  | narrative   | slow    | smooth   | False     | \n",
      "Harrison | Harrison | https://peregrine-samples.s3.amazonaws.com/editor-samples/Harrison.wav   | american | adult | male   | English (US) | en-US         | neutral  | narrative   | fast    | round    | False     | \n",
      "hayden   | Cooper   | https://peregrine-samples.s3.amazonaws.com/editor-samples/hayden.wav     | american | adult | male   | English (US) | en-US         | neutral  | narrative   | neutral | round    | False     | \n",
      "Hudson   | Hudson   | https://peregrine-samples.s3.amazonaws.com/editor-samples/Hudson.wav     | american | adult | male   | English (US) | en-US         | neutral  | videos      | neutral | thick    | False     | \n",
      "jarrett  | Jarrett  | https://peregrine-samples.s3.amazonaws.com/editor-samples/jarrett.wav    | american | adult | male   | English (US) | en-US         | low      | advertising | slow    | smooth   | False     | \n",
      "jerrell  | Jerrell  | https://peregrine-samples.s3.amazonaws.com/editor-samples/jerrell.wav    | american | adult | male   | English (US) | en-US         | low      | narrative   | neutral | round    | False     | \n",
      "jordan   | Jordan   | https://peregrine-samples.s3.amazonaws.com/editor-samples/jordan.wav     | american | adult | male   | English (US) | en-US         | neutral  | training    | slow    | round    | False     | \n",
      "judson   | Judson   | https://peregrine-samples.s3.amazonaws.com/editor-samples/judson.wav     | american | adult | male   | English (US) | en-US         | low      | narrative   | slow    | smooth   | False     | \n",
      "Julian   | Julian   | https://peregrine-samples.s3.amazonaws.com/editor-samples/Julian.wav     | american | adult | male   | English (US) | en-US         | neutral  | videos      | neutral | round    | False     | \n",
      "larry    | Larry    | https://peregrine-samples.s3.amazonaws.com/editor-samples/larry.wav      | american | adult | male   | English (US) | en-US         | neutral  | narrative   | neutral | smooth   | False     | \n",
      "Owen     | Owen     | https://peregrine-samples.s3.amazonaws.com/editor-samples/Owen.wav       | american | youth | male   | English (US) | en-US         | high     | narrative   | neutral | round    | False     | \n",
      "pedro    | Pedro    | https://peregrine-samples.s3.amazonaws.com/editor-samples/pedro.wav      | american | adult | male   | English (US) | en-US         | neutral  | narrative   | slow    | round    | False     | \n",
      "rodrick  | Rodrick  | https://peregrine-samples.s3.amazonaws.com/editor-samples/rodrick.wav    | american | adult | male   | English (US) | en-US         | neutral  | narrative   | neutral | smooth   | False     | \n",
      "wilbur   | Wilbur   | https://peregrine-samples.s3.amazonaws.com/editor-samples/wilbur.wav     | american | youth | male   | English (US) | en-US         | neutral  | narrative   | neutral | smooth   | False     | \n",
      "william  | William  | https://peregrine-samples.s3.amazonaws.com/editor-samples/william_vo.wav | american | adult | male   | English (US) | en-US         | neutral  | videos      | neutral | round    | False     | \n"
     ]
    }
   ],
   "source": [
    "# Define your filter\n",
    "filter_dict = {\n",
    "    # \"name\": \"\"\n",
    "    \"accent\": [\"american\", \"canadian\"],  # \"british\", \"american\", \"canadian\"\n",
    "    \"age\": [\"youth\", \"adult\"],  # \"youth\", \"adult\", \"old\"\n",
    "    \"gender\": [\"male\"],  # \"male\", \"female\"\n",
    "    # \"loudness\": [\"low\", \"neutral\", \"high\"],  # \"low\", \"neutral\", \"high\"\n",
    "    # \"style\": [\"narrative\"],  # \"narrative\", \"videos\", \"training\", \"advertising\"\n",
    "    # \"tempo\": [\"fast\"],  # \"slow\", \"neutral\", \"fast\"\n",
    "    # \"texture\": [\"smooth\", \"round\", \"thick\", \"gravelly\"]  # \"smooth\", \"round\", \"thick\", \"gravelly\"\n",
    "}\n",
    "\n",
    "# Filter voices\n",
    "filtered_voices = playht.filter_voices(filter_dict)\n",
    "\n",
    "# Print filtered voices\n",
    "playht.print_voices(filtered_voices)\n",
    "\n",
    "voice_ids = playht.get_attribute_list('id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting threads: 100%|██████████| 13/13 [01:21<00:00,  6.29s/it]\n"
     ]
    }
   ],
   "source": [
    "board = Board(BOARD_URL)\n",
    "\n",
    "board.save_chunks(\"data/board_chunks\", chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_red(content, character):\n",
    "    \"\"\"\n",
    "    This function checks the given content for conditions that will mark the block as 'red'.\n",
    "    \"\"\"\n",
    "    # Check if content contains math equations\n",
    "    if re.search(r'\\$[^$]*\\$', content):  # Simple check for LaTeX equations\n",
    "        return True\n",
    "    \n",
    "    # Check if content contains certain HTML tags\n",
    "    tags_to_check = ['img', 'big', 'small', 'details', 'hr', 'span']\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    for tag in tags_to_check:\n",
    "        if soup.find(tag):\n",
    "            return True\n",
    "    \n",
    "    # Check if there are no authors (so only narrator) yet there are quotes in the block\n",
    "    text = BeautifulSoup(content, 'html.parser').get_text()\n",
    "    if character is None and '\"' in text:\n",
    "        return True\n",
    "    \n",
    "    if character not in VOICE_DICT.keys():\n",
    "        return True\n",
    "    \n",
    "    # [Add other checks here]\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove strange strings like '\\u00a0' and replace with space\n",
    "    cleaned_text = text.replace('\\u00a0', ' ').replace('\\xa0', ' ').replace('  ', ' ')\n",
    "    return cleaned_text\n",
    "\n",
    "def contains_english_word(s):\n",
    "    # Check if the string contains any English word using a regular expression\n",
    "    return re.search(r'\\b[A-Za-z]+\\b', s) is not None\n",
    "\n",
    "def separate_speech(block_text, character_name, narrator_name):\n",
    "    results = []\n",
    "    \n",
    "    if character_name is None:\n",
    "        text = block_text.split('\\n')\n",
    "        for t in text:\n",
    "            if contains_english_word(t):\n",
    "                results.append({'name': narrator_name, 'text': clean_text(t)})\n",
    "        return results\n",
    "    \n",
    "    # Split text into speech sections, delimited by quotes\n",
    "    speeches = re.split(r'(\".*?\")', block_text)\n",
    "    \n",
    "    for i, speech in enumerate(speeches):\n",
    "        speech = speech.strip()\n",
    "        if not speech:\n",
    "            continue\n",
    "        name = narrator_name if i % 2 == 0 else character_name\n",
    "        text = clean_text(speech[1:-1]) if name == character_name else clean_text(speech)\n",
    "        \n",
    "        # Split text by paragraph\n",
    "        text = text.split('\\n')\n",
    "        for t in text:\n",
    "            if contains_english_word(t):\n",
    "                results.append({'name': name, 'text': clean_text(t)})\n",
    "    return results\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_blocks(folder_path):\n",
    "    def extract_number(filename):\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        return int(match.group()) if match else float('inf')\n",
    "\n",
    "    json_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.json')], key=extract_number)\n",
    "\n",
    "    for json_file in tqdm(json_files):\n",
    "        try:\n",
    "            with open(f\"{folder_path}/{json_file}\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from file: {json_file}\")\n",
    "            raise e\n",
    "\n",
    "        for block in data:\n",
    "            plain_text = html_to_plain_text(block['content'])\n",
    "            new_voices = []\n",
    "\n",
    "            for voice in separate_speech(plain_text, block['character'], \"Narrator\"):\n",
    "                new_voices.append({\n",
    "                    'name': voice['name'],\n",
    "                    'text': voice['text']\n",
    "                })\n",
    "            block['voices'] = new_voices\n",
    "            block['red'] = check_red(block['content'], block['character'])\n",
    "        with open(f\"{folder_path}/{json_file}\", \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:31<00:00,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "update_blocks(BOARDS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first function prepares the input for the generate_audio function\n",
    "def prepare_text_groups(data):\n",
    "    text_groups = []\n",
    "    for block in data:\n",
    "        for voice in block['voices']:\n",
    "            voice_id = VOICE_DICT[voice['name']]\n",
    "            if voice_id not in voice_ids:\n",
    "                print(f\"Invalid voice: \\\"{voice}\\\"\")\n",
    "                print(f\"Voice ID: {voice_id}\")\n",
    "                raise ValueError(f\"Invalid voice ID: {voice_id}\")\n",
    "            text_group = {\n",
    "                'text': voice['text'], \n",
    "                'voice': voice_id,\n",
    "            }\n",
    "            text_groups.append(text_group)\n",
    "    return text_groups\n",
    "\n",
    "# The third function updates the original JSON data with the processed output\n",
    "def update_json(original_data, processed_output):\n",
    "    output_index = 0\n",
    "    for block in original_data:\n",
    "        for voice in block['voices']:\n",
    "            voice['audio'] = processed_output[output_index]['url']\n",
    "            voice['duration'] = processed_output[output_index]['duration']\n",
    "            output_index += 1\n",
    "    return original_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_audio_for_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    n = 50  # The size of each chunk\n",
    "    for i in range(0, len(data), n):\n",
    "        text_groups = prepare_text_groups(data[i:i+n])\n",
    "\n",
    "        # As this script is meant to be run in an async environment,\n",
    "        # 'await' is required before calling generate_audio.\n",
    "        audio_output = await generate_audio(text_groups)\n",
    "        processed_output = process_output(audio_output)\n",
    "        updated_data = update_json(data[i:i+n], processed_output)\n",
    "\n",
    "        # Save updated data back to the file after every chunk\n",
    "        data[i:i+n] = updated_data\n",
    "        with open(filepath, 'w') as file:\n",
    "            json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{BOARDS_PATH}/planecrash_chunk_1_of_203.json'\n",
    "\n",
    "# Load JSON data\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)[:10]\n",
    "\n",
    "# Prepare text groups for generate_audio function\n",
    "text_groups = prepare_text_groups(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_output = await generate_audio(text_groups)\n",
    "processed_output = process_output(audio_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = update_json(data, processed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(updated_data, file, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "print(\"http://localhost:5000/\")\n",
    "%run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
